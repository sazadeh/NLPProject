{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: \n",
    "# Evaluating Doc2Vec Model based on Sentiment Analysis on IMDB DataSet (Using Gensim)\n",
    "\n",
    "#### Members:Sara Azadeh, Lesley Milley\n",
    "\n",
    "####  Emails: sara.azadeh@ryerson.ca , Lesley.milley@ryerson.ca \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Many ML algorithms require the input to be represented as a fixed-length feature vector and bag-of-word was one of the common fixed-length feature but it has some weaknesses. \n",
    "\n",
    "#### Context of the Problem:\n",
    "We want to be able to predict topics,labels and sentiments and the problem is how to use the information which we have to make the best prediction.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "Bag-of-words has two major weakness: \n",
    "1)Lose ordering of words 2) Ignore semantics of words\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "Paragraph Vector is an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "Train a variety of Doc2Vec models on the imdb dataset.\n",
    "Evaluate the performance of each model in predicting sentiment using a variety of machin learning algorithm.\n",
    "\n",
    "Our starting point was to replicate part of the papers listed below which includes the original papers on Doc2Vec concept.\n",
    "We chose to test the application of Doc2Vec on sentiment analysis.\n",
    "The Auhtors did not publish their codes .However there were several implementations of their papers. We chose one of those implementation as a baseline.\n",
    "That implemenation trained the models based on Gensim(Doc2Vec) and then assess the sentiments uning the Logistic Regression. We expanded that assess the sentiment using RandomForest Classifier and GaussianNB.<br />\n",
    "*Other papers mentioned the difficulty in replicating the original papers both for accuracy and in terms of the best models and hyperparameters.We performed several experiments to determin the best Doc2Vec model in predicting sentiment.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    " Many ML algorithms require the input to be presented as a fixed-length feature vector. (Bag-Of-Words one of the most common fixed-length feature)\n",
    "\n",
    "Bag-Of-Words has two major weaknesses: \n",
    "\n",
    " *Loses the  ordering of words\n",
    " \n",
    " *Ignores semantics of words\n",
    " \n",
    "Paragraph Vector is an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of text\n",
    " In this algorithm each document is represented by a dense vector which is trained by predicting words in the document. \n",
    "This method overcomes the Bag-Of-Words weaknesses\n",
    "\n",
    "| Reference |Explanation |  Dataset/Input |Weaknesses\n",
    "| --- | --- | --- | --- |\n",
    "| Andrew M. Dai et al. [1] | Paragraph Vectors can effectively be used for measuring semantic similarity between long pieces of texts| arXiv article , Wikipedia| They only used the DBOW model\n",
    "| Quoc V. Le et al. [2] | Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations| Treebank Dataset , Imdb Dataset | Cannot be replicated (Others struggle to reproduce the results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For a single document we keep: \n",
    "\n",
    "* words: The text of the document, as a ``list`` of words.\n",
    "* tags: Used to keep the index of the document in the entire dataset.\n",
    "* split: one of ``train``\\ , ``test`` or ``extra``. Determines how the document will be used (for training, testing, etc).\n",
    "* sentiment: either 1 (positive), 0 (negative) or None (unlabeled document).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "SentimentDocument = collections.namedtuple('SentimentDocument', 'words tags split sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part we load the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "import smart_open\n",
    "import gensim.utils\n",
    "\n",
    "\n",
    "def download_dataset(url='http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'):\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    if os.path.isfile(fname):\n",
    "        return fname\n",
    "\n",
    "    # Download the file to local storage first.\n",
    "    with smart_open.open(url, \"rb\", ignore_ext=True) as fin:\n",
    "        with smart_open.open(fname, 'wb', ignore_ext=True) as fout:\n",
    "            while True:\n",
    "                buf = fin.read(io.DEFAULT_BUFFER_SIZE)\n",
    "                if not buf:\n",
    "                    break\n",
    "                fout.write(buf)\n",
    "\n",
    "    return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_document(name, text, index):\n",
    "    _, split, sentiment_str, _ = name.split('/')\n",
    "    sentiment = {'pos': 1.0, 'neg': 0.0, 'unsup': None}[sentiment_str]\n",
    "\n",
    "    if sentiment is None:\n",
    "        split = 'extra'\n",
    "\n",
    "    tokens = gensim.utils.to_unicode(text).split()\n",
    "    \n",
    "    return SentimentDocument(tokens, [index], split, sentiment)\n",
    "\n",
    "def extract_documents():\n",
    "    fname = download_dataset()\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if re.match(r'aclImdb/(train|test)/(pos|neg|unsup)/\\d+_\\d+.txt$', member.name):\n",
    "                member_bytes = tar.extractfile(member).read()\n",
    "                member_text = member_bytes.decode('utf-8', errors='replace')\n",
    "                assert member_text.count('\\n') == 0\n",
    "                yield create_sentiment_document(member.name, member_text, index)\n",
    "                index += 1\n",
    "\n",
    "alldocs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a single document looks like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentDocument(words=['I', 'was', 'looking', 'forward', 'to', 'this', 'movie.', 'Trustworthy', 'actors,', 'interesting', 'plot.', 'Great', 'atmosphere', 'then', '?????', 'IF', 'you', 'are', 'going', 'to', 'attempt', 'something', 'that', 'is', 'meant', 'to', 'encapsulate', 'the', 'meaning', 'of', 'life.', 'First.', 'Know', 'it.', 'OK', 'I', 'did', 'not', 'expect', 'the', 'directors', 'or', 'writers', 'to', 'actually', 'know', 'the', 'meaning', 'but', 'I', 'thought', 'they', 'may', 'have', 'offered', 'crumbs', 'to', 'peck', 'at', 'and', 'treats', 'to', 'add', 'fuel', 'to', 'the', 'fire-Which!', 'they', 'almost', 'did.', 'Things', 'I', \"didn't\", 'get.', 'A', 'woman', 'wandering', 'around', 'in', 'dark', 'places', 'and', 'lonely', 'car', 'parks', 'alone-oblivious', 'to', 'the', 'consequences.', 'Great', 'riddles', 'that', 'fell', 'by', 'the', 'wayside.', 'The', 'promise', 'of', 'the', 'knowledge', 'therein', 'contained', 'by', 'the', 'original', 'so-called', 'criminal.', 'I', 'had', 'no', 'problem', 'with', 'the', 'budget', 'and', 'enjoyed', 'the', 'suspense.', 'I', 'understood', 'and', 'can', 'wax', 'lyrical', 'about', 'the', 'fool', 'and', 'found', 'Adrian', 'Pauls', 'role', 'crucial', 'and', 'penetrating', 'and', 'then', '?????', 'Basically', 'the', 'story', 'line', 'and', 'the', 'script', 'where', 'good', 'up', 'to', 'a', 'point', 'and', 'that', 'point', 'was', 'the', 'last', '10', 'minutes', 'or', 'so.', 'What?', 'Run', 'out', 'of', 'ideas!', 'Such', 'a', 'pity', 'that', 'this', 'movie', 'had', 'to', 'let', 'us', 'down', 'so', 'badly.', 'It', 'may', 'not', 'comprehend', 'the', 'meaning', 'and', 'I', 'really', 'did', 'not', 'expect', 'the', 'writers', 'to', 'understand', 'it', 'but', 'I', 'was', 'hoping', 'for', 'an', 'intellectual,', 'if', 'not', 'spiritual', 'ride', 'and', 'got', 'a', 'bump', 'in', 'the', 'road'], tags=[27], split='test', sentiment=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(alldocs[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract our documents and split into training/test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "print(f'{len(alldocs)} docs: {len(train_docs)} train-sentiment, {len(test_docs)} test-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentDocument(words=['I', 'rented', 'I', 'AM', 'CURIOUS-YELLOW', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it', 'was', 'first', 'released', 'in', '1967.', 'I', 'also', 'heard', 'that', 'at', 'first', 'it', 'was', 'seized', 'by', 'U.S.', 'customs', 'if', 'it', 'ever', 'tried', 'to', 'enter', 'this', 'country,', 'therefore', 'being', 'a', 'fan', 'of', 'films', 'considered', '\"controversial\"', 'I', 'really', 'had', 'to', 'see', 'this', 'for', 'myself.<br', '/><br', '/>The', 'plot', 'is', 'centered', 'around', 'a', 'young', 'Swedish', 'drama', 'student', 'named', 'Lena', 'who', 'wants', 'to', 'learn', 'everything', 'she', 'can', 'about', 'life.', 'In', 'particular', 'she', 'wants', 'to', 'focus', 'her', 'attentions', 'to', 'making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average', 'Swede', 'thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'Vietnam', 'War', 'and', 'race', 'issues', 'in', 'the', 'United', 'States.', 'In', 'between', 'asking', 'politicians', 'and', 'ordinary', 'denizens', 'of', 'Stockholm', 'about', 'their', 'opinions', 'on', 'politics,', 'she', 'has', 'sex', 'with', 'her', 'drama', 'teacher,', 'classmates,', 'and', 'married', 'men.<br', '/><br', '/>What', 'kills', 'me', 'about', 'I', 'AM', 'CURIOUS-YELLOW', 'is', 'that', '40', 'years', 'ago,', 'this', 'was', 'considered', 'pornographic.', 'Really,', 'the', 'sex', 'and', 'nudity', 'scenes', 'are', 'few', 'and', 'far', 'between,', 'even', 'then', \"it's\", 'not', 'shot', 'like', 'some', 'cheaply', 'made', 'porno.', 'While', 'my', 'countrymen', 'mind', 'find', 'it', 'shocking,', 'in', 'reality', 'sex', 'and', 'nudity', 'are', 'a', 'major', 'staple', 'in', 'Swedish', 'cinema.', 'Even', 'Ingmar', 'Bergman,', 'arguably', 'their', 'answer', 'to', 'good', 'old', 'boy', 'John', 'Ford,', 'had', 'sex', 'scenes', 'in', 'his', 'films.<br', '/><br', '/>I', 'do', 'commend', 'the', 'filmmakers', 'for', 'the', 'fact', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money', 'to', 'be', 'shown', 'in', 'pornographic', 'theaters', 'in', 'America.', 'I', 'AM', 'CURIOUS-YELLOW', 'is', 'a', 'good', 'film', 'for', 'anyone', 'wanting', 'to', 'study', 'the', 'meat', 'and', 'potatoes', '(no', 'pun', 'intended)', 'of', 'Swedish', 'cinema.', 'But', 'really,', 'this', 'film', \"doesn't\", 'have', 'much', 'of', 'a', 'plot.'], tags=[25000], split='train', sentiment=0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Set-up Doc2Vec Training & Evaluation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t4) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import multiprocessing\n",
    "from collections import OrderedDict\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "# cbow=0 means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with dm=0\n",
    "\n",
    "#A min_count=2 saves quite a bit of model memory, discarding only words that appear in a single doc\n",
    "\n",
    "# In the paper they used vector sized of 400 and we reduced it to 100 and also we considered 10 epochs\n",
    "#We changed some parameters here  when we want to make a model to have better performance\n",
    "\n",
    "common_kwargs = dict(\n",
    "    vector_size=100, epochs=10, min_count=2,\n",
    "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0\n",
    ")\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, alpha=0.025 ,min_alpha = 0.0001 ,**common_kwargs),\n",
    "    \n",
    "    # PV-DM plain w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    # The initial learning rate = alpha\n",
    "\n",
    "    Doc2Vec(dm=1, window=10, alpha=0.025,min_alpha = 0.0001, comment='alpha=0.05', **common_kwargs),\n",
    "    \n",
    "    # PV-DM w/ concatenation window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "      \n",
    "    Doc2Vec(dm=1, dm_concat=1, window=5,alpha=0.025,min_alpha = 0.0001, **common_kwargs),\n",
    "  \n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(f\"{model} vocabulary scanned & state initialized\")\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what described in paper combining a paragraph vector from Distributed Bag of Words (DBOW) and Distributed Memory (DM) improves performance at this part we paired different simple models which is built above and try to make new combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Evaluation Method\n",
    "\n",
    "We will have three experiments:\n",
    "\n",
    "1) The first one will be using logestic Regression to predict the sentiments and also Evaluate the Models and sort the Error Rates to find the best model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "\n",
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    predictor = logit.fit(disp=0)\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_regressors = [test_model.dv[doc.tags[0]] for doc in train_set]\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_regressors = [test_model.dv[doc.tags[0]] for doc in test_set]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "\n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_set])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Running this part takes about almost 1 hour!!! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "error_rates = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train our Simple Doc2Vec models and Evluate the results: (Based on Logistic Regression)\n",
      "\n",
      "Training Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "0.104920 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.186120 Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.354520 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Train our Combined Doc2Vec models and Evluate the results: (Based on Logistic Regression)\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.10464 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.10564 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffled_alldocs = alldocs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "\n",
    "print(\"Train our Simple Doc2Vec models and Evluate the results: (Based on Logistic Regression)\\n\")\n",
    "for model in simple_models:\n",
    "    print(f\"Training {model}\")\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))\n",
    "\n",
    "print(\"Train our Combined Doc2Vec models and Evluate the results: (Based on Logistic Regression)\\n\")\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(f\"\\n{err_rate} {model}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part we sort our models based on the acquired Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate and Model Name: (Based on Logistic Regression)\n",
      "\n",
      "0.10464 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.10492 \t Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "0.10564 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "0.18612 \t Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.35452 \t Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate and Model Name: (Based on Logistic Regression)\\n\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
    "    print(f\"{rate} \\t {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The second one will be using Random Forest to predict the sentiments and also Evaluate the Models and sort the Error Rates to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def RandomForest_predictor_from_data(train_targets, train_regressors):\n",
    " \n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    \n",
    "    predictor = clf.fit(train_regressors,train_targets)\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_ranndomforest_model(test_model, train_set, test_set):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_regressors = [test_model.dv[doc.tags[0]] for doc in train_set]\n",
    "    predictor = RandomForest_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_regressors = [test_model.dv[doc.tags[0]] for doc in test_set]\n",
    "\n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_set])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Running this part takes about almost 1 hour!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "error_rates_rf = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train our Simple Doc2Vec models and Evluate the results (Based on RandomForest):\n",
      "\n",
      "Training Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "0.215840 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.273120 Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.356240 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Train our Combined Doc2Vec models and Evluate the results (Based on RandomForest):\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.23804 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.21232 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffled_alldocs = alldocs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "\n",
    "print(\"Train our Simple Doc2Vec models and Evluate the results (Based on RandomForest):\\n\")\n",
    "for model in simple_models:\n",
    "    print(f\"Training {model}\")\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_ranndomforest_model(model, train_docs, test_docs)\n",
    "    error_rates_rf[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))\n",
    "\n",
    "print(\"Train our Combined Doc2Vec models and Evluate the results (Based on RandomForest):\\n\")\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_ranndomforest_model(model, train_docs, test_docs)\n",
    "    error_rates_rf[str(model)] = err_rate\n",
    "    print(f\"\\n{err_rate} {model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate and Model Name: (Based on RandomForest)\n",
      "\n",
      "0.21232 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "0.21584 \t Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "0.23804 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.27312 \t Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.35624 \t Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate and Model Name: (Based on RandomForest)\\n\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates_rf.items()):\n",
    "    print(f\"{rate} \\t {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The third one will be using GaussianNB to predict the sentiments and also Evaluate the Models and sort the Error Rates to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def GaussianNB_predictor_from_data(train_targets, train_regressors):\n",
    " \n",
    "    clf = GaussianNB()\n",
    "    predictor = clf.fit(train_regressors,train_targets)\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_GaussianNB_model(test_model, train_set, test_set):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    train_regressors = [test_model.dv[doc.tags[0]] for doc in train_set]\n",
    "    predictor = GaussianNB_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_regressors = [test_model.dv[doc.tags[0]] for doc in test_set]\n",
    "\n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_set])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Running this part takes about almost 1 hour!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "error_rates_NB = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train our Simple Doc2Vec models and Evluate the results (Based on GaussianNB):\n",
      "\n",
      "Training Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "0.126560 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.258960 Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.277520 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "Train our Combined Doc2Vec models and Evluate the results (Based on GaussianNB):\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "0.17052 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n",
      "0.15196 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffled_alldocs = alldocs[:]\n",
    "shuffle(shuffled_alldocs)\n",
    "\n",
    "print(\"Train our Simple Doc2Vec models and Evluate the results (Based on GaussianNB):\\n\")\n",
    "for model in simple_models:\n",
    "    print(f\"Training {model}\")\n",
    "    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n",
    "\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_GaussianNB_model(model, train_docs, test_docs)\n",
    "    error_rates_NB[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))\n",
    "\n",
    "print(\"Train our Combined Doc2Vec models and Evluate the results (Based on GaussianNB):\\n\")\n",
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n",
    "    print(f\"\\nEvaluating {model}\")\n",
    "    err_rate, err_count, test_count, predictor = error_rate_for_GaussianNB_model(model, train_docs, test_docs)\n",
    "    error_rates_NB[str(model)] = err_rate\n",
    "    print(f\"\\n{err_rate} {model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate and Model Name: (Based on GaussianNB)\n",
      "\n",
      "0.12656 \t Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "0.15196 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "0.17052 \t Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.25896 \t Doc2Vec(dm/m,d100,n5,w10,mc2,t4)\n",
      "0.27752 \t Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate and Model Name: (Based on GaussianNB)\\n\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates_NB.items()):\n",
    "    print(f\"{rate} \\t {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "The Doc2Vec is a strong methodology for predicting sentiments.However the model has to be chosen carefully and it has to be tuned.\n",
    "The original papers indicated that a more complex concatenated models had the lowest error rate however we found that the simpler DBOW Model was the same or better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this part we try to compare all the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names= [\"Error_rate_LR\",\"Error_rate_RF\",\"Error_rate_GBN\"]\n",
    "df = pd.DataFrame(columns = column_names , index = error_rates_NB.keys())\n",
    "df.index.name = \"Models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Error_rate_GBN\"] = error_rates_NB.values()\n",
    "df[\"Error_rate_RF\"] = error_rates_rf.values()\n",
    "df[\"Error_rate_LR\"]=error_rates.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_rate_LR</th>\n",
       "      <th>Error_rate_RF</th>\n",
       "      <th>Error_rate_GBN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc2Vec(dbow,d100,n5,mc2,t4)</th>\n",
       "      <td>0.10492</td>\n",
       "      <td>0.21584</td>\n",
       "      <td>0.12656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec(dm/m,d100,n5,w10,mc2,t4)</th>\n",
       "      <td>0.18612</td>\n",
       "      <td>0.27312</td>\n",
       "      <td>0.25896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec(dm/c,d100,n5,w5,mc2,t4)</th>\n",
       "      <td>0.35452</td>\n",
       "      <td>0.35624</td>\n",
       "      <td>0.27752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,n5,w10,mc2,t4)</th>\n",
       "      <td>0.10464</td>\n",
       "      <td>0.23804</td>\n",
       "      <td>0.17052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)</th>\n",
       "      <td>0.10564</td>\n",
       "      <td>0.21232</td>\n",
       "      <td>0.15196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Error_rate_LR  \\\n",
       "Models                                                              \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)                              0.10492   \n",
       "Doc2Vec(dm/m,d100,n5,w10,mc2,t4)                          0.18612   \n",
       "Doc2Vec(dm/c,d100,n5,w5,mc2,t4)                           0.35452   \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,...        0.10464   \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,...        0.10564   \n",
       "\n",
       "                                                    Error_rate_RF  \\\n",
       "Models                                                              \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)                              0.21584   \n",
       "Doc2Vec(dm/m,d100,n5,w10,mc2,t4)                          0.27312   \n",
       "Doc2Vec(dm/c,d100,n5,w5,mc2,t4)                           0.35624   \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,...        0.23804   \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,...        0.21232   \n",
       "\n",
       "                                                    Error_rate_GBN  \n",
       "Models                                                              \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)                               0.12656  \n",
       "Doc2Vec(dm/m,d100,n5,w10,mc2,t4)                           0.25896  \n",
       "Doc2Vec(dm/c,d100,n5,w5,mc2,t4)                            0.27752  \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/m,d100,...         0.17052  \n",
       "Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,...         0.15196  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1]:  Authors Andrew M. Dai, Christopher Olah, Quoc V. Le, Document Embedding with Paragraph Vectors \n",
    "\n",
    "[2]:  Author Quoc V. Le, Tomas Mikolov, Distributed Representations of Sentences and Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References: \n",
    "#https://radimrehurek.com/gensim/auto_examples/howtos/run_doc2vec_imdb.html#sphx-glr-download-auto-examples-howtos-run-doc2vec-imdb-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
